
2021/04/13

Task is to get a count of three-word sequences from an input body of text.

Pipe in from stdin, or read in from an arbitrary number of files provided by
argument.

. Iterate through lines per input file
	. Each provides blocks of text ending with whole words
	. Iterate through words per block of text
		. pass n number of words at a time?
		. no, pass a list or tuple of n words
			. but only slide the cursor along one word at a time
		. gotta pass the last sequence from the previous block in

We're supposed to have a count of the K most common sequences.

Should I store *all* sequences in a table?

Implementing a tree would save on memory...

Storing only the top most common sequences could work, except... no, if the
least common sequence suddenly happens a million times in a row, it'd need to
already be in the table.

For now, let's keep the full count table as we go along, then sort that for the
final answer.

Unless we use a heap sort insert as we go along?

Just use a dictionary to start with.  Keep things simple and successfully tested
before getting all fancy.

Downloaded origin-of-species.txt, and ran this against it, placing the output
under the test/ directory.

Far as I can tell, it's working.  Input via pipe and files specified 

Am I supposed to title the file solution.py?  Or was that simply an example?

Tests...

python3 comseq.py test/origin-of-species.txt > test/origin-of-species.out
python3 comseq.py test/quick-test.txt test/quick-test-2.txt > test/quick-tests.out


